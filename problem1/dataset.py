"""
Dataset loader for font generation task.
Supports two metadata formats:
1) fonts_metadata.json  (teacher's format)
   {
     "train": [{"path": "fonts/train/A_bold_0000.png", "letter": "A", "font": 1}, ...],
     "val":   [...]
   }

2) fonts/metadata.json  (generated by setup_data.py you provided)
   {
     "letters": ["A",...,"Z"],
     "font_styles": [...],
     "image_size": 28,
     "train_samples": [{"filename": "...", "letter": "A", "letter_idx": 0, ...}, ...],
     "val_samples":   [...]
   }
"""

from __future__ import annotations
import os
import json
from pathlib import Path
from typing import Literal, Tuple

import numpy as np
import torch
from torch import Tensor
from torch.utils.data import Dataset
from PIL import Image


class FontDataset(Dataset):
    def __init__(
        self,
        data_dir: str | os.PathLike,
        split: Literal["train", "val"] = "train",
        normalize: Literal["zero_one", "neg_one_one"] = "zero_one",
        enforce_size: int = 28,
    ):
        """
        Args:
        data_dir: Root directory (points to the folder containing fonts/, e.g., hw2-starter/data)
        split: 'train' or 'val'
        normalize:
        - 'zero_one' -> output range [0, 1]
        - 'neg_one_one' -> output range [-1, 1] (common for GANs; tanh-friendly)
        enforce_size: Target image height/width (default 28)
        """
        self.data_dir = Path(data_dir)
        self.split = split
        self.normalize = normalize
        self.enforce_size = enforce_size

        assert self.split in ("train", "val"), f"split must be 'train' or 'val', got {self.split}"
        assert self.data_dir.exists(), f"data_dir not found: {self.data_dir}"


        meta_teacher = self.data_dir / "fonts_metadata.json"
        meta_generated = self.data_dir / "metadata.json"

        if meta_teacher.exists():
            self._load_teacher_metadata(meta_teacher)
        elif meta_generated.exists():
            self._load_generated_metadata(meta_generated)
        else:
            raise FileNotFoundError(
                f"Cannot find metadata. Tried:\n  - {meta_teacher}\n  - {meta_generated}"
            )


        self.letter_to_id = {chr(65 + i): i for i in range(26)}


        assert len(self.samples) > 0, f"No samples for split={self.split}"

        first_path = self._resolve_path(self.samples[0])
        assert first_path.exists(), f"Sample file not found: {first_path}"

    # -------- metadata loaders --------
    def _load_teacher_metadata(self, meta_path: Path) -> None:

        with open(meta_path, "r", encoding="utf-8") as f:
            metadata = json.load(f)

        if self.split not in metadata:
            raise KeyError(f"Key '{self.split}' missing in {meta_path}")
        self.samples = metadata[self.split]
        self.format = "teacher"

    def _load_generated_metadata(self, meta_path: Path) -> None:

        with open(meta_path, "r", encoding="utf-8") as f:
            metadata = json.load(f)

        key = f"{self.split}_samples"
        if key not in metadata:
            raise KeyError(f"Key '{key}' missing in {meta_path}")
        self.samples = metadata[key]
        self.format = "generated"

    # -------- path resolver --------
    def _resolve_path(self, sample: dict) -> Path:

        if self.format == "teacher":

            return self.data_dir / sample["path"]
        else:

            return self.data_dir / self.split / sample["filename"]

    # -------- dataset API --------
    def __len__(self) -> int:
        return len(self.samples)

    def __getitem__(self, idx: int) -> Tuple[Tensor, int]:
        sample = self.samples[idx]
        img_path = self._resolve_path(sample)


        with Image.open(img_path) as im:
            im = im.convert("L")
            # enforce_size
            if im.size != (self.enforce_size, self.enforce_size):
                im = im.resize((self.enforce_size, self.enforce_size), Image.LANCZOS)

            img = np.asarray(im, dtype=np.float32)  # 0..255


        if self.normalize == "zero_one":
            img = img / 255.0  # [0,1]
        elif self.normalize == "neg_one_one":
            img = img / 255.0 * 2.0 - 1.0  # [-1,1]
        else:
            raise ValueError(f"Unknown normalize mode: {self.normalize}")


        img_t = torch.from_numpy(img).unsqueeze(0)


        if self.format == "teacher":
            letter = sample["letter"]
        else:

            letter = sample["letter"]
        letter_id = self.letter_to_id[letter]

        return img_t, letter_id
